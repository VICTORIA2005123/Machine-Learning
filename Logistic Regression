import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
dataset=pd.read_csv('/content/diabetes.csv')
dataset.describe()
dataset.head()
feature_col=['Glucose','BloodPressure','Insulin','BMI','DiabetesPedigreeFunction','Age']
X=dataset[feature_col]
y=dataset.Outcome
#train-Test Split
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2,random_state=16)
#standard scaler
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.transform(X_test)
from sklearn.linear_model import LogisticRegression
model=LogisticRegression(max_iter=1000)
model.fit(X_train_scaled,Y_train)
y_pred=model.predict(X_test_scaled)
y_pred
#efficiency or evaluation parameters
from sklearn import metrics
confusion_matrix=metrics.confusion_matrix(y_pred,Y_test)
confusion_matrix

def linear(x):
  return x

x=np.linspace(-10,10,200)
def plot_function(x,y,title):
  plt.plot(x,y,label=title)
  plt.title(title)
  plt.show()

plot_function(x,linear(x),"Linear Function")


def step(x):
  return np.where(x>=0,1,0)

x=np.linspace(-10,10,200)
def plot_function(x,y,title):
  plt.plot(x,y,label=title)
  plt.title(title)
  plt.show()

plot_function(x,step(x),"Step Function")

def relu(x):
  return np.maximum(0, x)

x=np.linspace(-10,10,200)
def plot_function(x,y,title):
  plt.plot(x,y,label=title)
  plt.title(title)
  plt.show()

plot_function(x,relu(x),"ReLU Function")

def tanh(x):
 return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))


x=np.linspace(-10,10,200)
def plot_function(x,y,title):
  plt.plot(x,y,label=title)
  plt.title(title)
  plt.show()

plot_function(x,tanh(x),"TanH Function")

def LeakyReLU(x):
 return np.maximum(0.01*x,x)

x=np.linspace(-10,10,200)
def plot_function(x,y,title):
  plt.plot(x,y,label=title)
  plt.title(title)
  plt.show()

plot_function(x,LeakyReLU(x),"Leaky ReLU Function")

def softmax(x):
  """Compute softmax values for each set of scores in x."""
  e1=(np.exp(x-np.max(x)))
  return (e1/np.sum(e1,axis=0))

z=np.array([0.90,0.10,0.40])
softmax(z)

plot_function(x,softmax(x),"Softmax Function")
